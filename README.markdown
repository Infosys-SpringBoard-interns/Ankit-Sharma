# Predicting Obesity Level using Machine Learning and Deep Learning

## Overview

This project was developed as part of the **Infosys Springboard 5.0 Internship**. The goal was to predict obesity levels using machine learning and deep learning techniques. I led a team of six members to preprocess data, perform exploratory data analysis (EDA), and train multiple classification models, achieving the highest accuracy with the TabNet neural network model.

- **Role**: Team Lead (6-member team)
- **Technologies Used**: Python, Scikit-learn, TabNet, MLflow, Pandas, NumPy, Matplotlib/Seaborn (for EDA)
- **Dataset**: \[Specify dataset, e.g., UCI Obesity Dataset or custom dataset\]

## Project Objectives

- Develop a classification model to predict obesity levels based on input features.
- Compare performance of machine learning (SVM, Random Forest, Logistic Regression) and deep learning (TabNet) models.
- Optimize model performance through hyperparameter tuning and track experiments using MLflow.

## Methodology

### 1. Data Preprocessing & EDA

- **Preprocessing**: Cleaned dataset, handled missing values, and performed feature engineering (e.g., encoding categorical variables, scaling numerical features).
- **EDA**: Conducted exploratory data analysis to identify key patterns and correlations (e.g., \[insert key insight, e.g., "BMI and physical activity strongly correlated with obesity levels"\]).
- Tools: Pandas, NumPy, Matplotlib, Seaborn.

### 2. Model Development

- **Models Evaluated**:
  - **Machine Learning**: Support Vector Machine (SVM), Random Forest, Logistic Regression.
  - **Deep Learning**: TabNet (a neural network-based model designed for tabular data).
- **Hyperparameter Tuning**: Used MLflow to track and visualize model performance across various hyperparameter configurations (e.g., learning rate, batch size for TabNet).
- **Evaluation Metrics**: Accuracy, \[add other metrics like precision, recall, F1-score if available\].

### 3. Results

- **Model Performance** (Update with your metrics):
  - TabNet: \[Insert accuracy, e.g., 85%\]
  - Random Forest: \[Insert accuracy, e.g., 82%\]
  - SVM: \[Insert accuracy, e.g., 80%\]
  - Logistic Regression: \[Insert accuracy, e.g., 78%\]
- **Key Insight**: TabNet outperformed traditional machine learning models after hyperparameter optimization, as visualized through MLflow dashboards.
- **MLflow Result Visualization**:
- ![Alt text](https://github.com/Infosys-SpringBoard-interns/Ankit-Sharma/blob/90b03c6b616f97b7169b44bcea414c25ef572ae5/tabnet_mlflow_result.jpg)

### 4. Video Demonstration

- [Watch the project presentation video](https://youtu.be/9TPm-FA387Q)

## Contributors

- Ankit Sharma
- Abhishek Mane
- Ankita Gupta
- Manvitha
- Himanshu
- Yamini
